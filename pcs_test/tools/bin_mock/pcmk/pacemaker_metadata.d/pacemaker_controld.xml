<?xml version="1.0"?><!DOCTYPE resource-agent SYSTEM "ra-api-1.dtd">
<resource-agent name="pacemaker-controld">
  <version>1.1</version>
  <longdesc lang="en">Cluster options used by Pacemaker&apos;s controller</longdesc>
  <shortdesc lang="en">Pacemaker controller options</shortdesc>
  <parameters>
    <parameter name="dc-version">
      <longdesc lang="en">Includes a hash which identifies the exact changeset the code was built from. Used for diagnostic purposes.</longdesc>
      <shortdesc lang="en">Pacemaker version on cluster node elected Designated Controller (DC)</shortdesc>
      <content type="string" default="none"/>
    </parameter>
    <parameter name="cluster-infrastructure">
      <longdesc lang="en">Used for informational and diagnostic purposes.</longdesc>
      <shortdesc lang="en">The messaging stack on which Pacemaker is currently running</shortdesc>
      <content type="string" default="corosync"/>
    </parameter>
    <parameter name="cluster-name">
      <longdesc lang="en">This optional value is mostly for users&apos; convenience as desired in administration, but may also be used in Pacemaker configuration rules via the #cluster-name node attribute, and by higher-level tools and resource agents.</longdesc>
      <shortdesc lang="en">An arbitrary name for the cluster</shortdesc>
      <content type="string" default="(null)"/>
    </parameter>
    <parameter name="dc-deadtime">
      <longdesc lang="en">The optimal value will depend on the speed and load of your network and the type of switches used.</longdesc>
      <shortdesc lang="en">How long to wait for a response from other nodes during start-up</shortdesc>
      <content type="time" default="20s"/>
    </parameter>
    <parameter name="cluster-recheck-interval">
      <longdesc lang="en">Pacemaker is primarily event-driven, and looks ahead to know when to recheck cluster state for failure timeouts and most time-based rules. However, it will also recheck the cluster after this amount of inactivity, to evaluate rules with date specifications and serve as a fail-safe for certain types of scheduler bugs.  Allowed values: Zero disables polling, while positive values are an interval in seconds(unless other units are specified, for example "5min")</longdesc>
      <shortdesc lang="en">Polling interval to recheck cluster state and evaluate rules with date specifications</shortdesc>
      <content type="time" default="15min"/>
    </parameter>
    <parameter name="load-threshold">
      <longdesc lang="en">The cluster will slow down its recovery process when the amount of system resources used (currently CPU) approaches this limit</longdesc>
      <shortdesc lang="en">Maximum amount of system load that should be used by cluster nodes</shortdesc>
      <content type="percentage" default="80%"/>
    </parameter>
    <parameter name="node-action-limit">
      <longdesc lang="en">Maximum number of jobs that can be scheduled per node (defaults to 2x cores)</longdesc>
      <shortdesc lang="en">Maximum number of jobs that can be scheduled per node (defaults to 2x cores)</shortdesc>
      <content type="integer" default="0"/>
    </parameter>
    <parameter name="fence-reaction">
      <longdesc lang="en">A cluster node may receive notification of its own fencing if fencing is misconfigured, or if fabric fencing is in use that doesn&apos;t cut cluster communication. Allowed values are &quot;stop&quot; to attempt to immediately stop Pacemaker and stay stopped, or &quot;panic&quot; to attempt to immediately reboot the local node, falling back to stop on failure.</longdesc>
      <shortdesc lang="en">How a cluster node should react if notified of its own fencing</shortdesc>
      <content type="string" default="stop"/>
    </parameter>
    <parameter name="election-timeout">
      <longdesc lang="en">Declare an election failed if it is not decided within this much time. If you need to adjust this value, it probably indicates the presence of a bug.</longdesc>
      <shortdesc lang="en">*** Advanced Use Only ***</shortdesc>
      <content type="time" default="2min"/>
    </parameter>
    <parameter name="shutdown-escalation">
      <longdesc lang="en">Exit immediately if shutdown does not complete within this much time. If you need to adjust this value, it probably indicates the presence of a bug.</longdesc>
      <shortdesc lang="en">*** Advanced Use Only ***</shortdesc>
      <content type="time" default="20min"/>
    </parameter>
    <parameter name="join-integration-timeout">
      <longdesc lang="en">If you need to adjust this value, it probably indicates the presence of a bug.</longdesc>
      <shortdesc lang="en">*** Advanced Use Only ***</shortdesc>
      <content type="time" default="3min"/>
    </parameter>
    <parameter name="join-finalization-timeout">
      <longdesc lang="en">If you need to adjust this value, it probably indicates the presence of a bug.</longdesc>
      <shortdesc lang="en">*** Advanced Use Only ***</shortdesc>
      <content type="time" default="30min"/>
    </parameter>
    <parameter name="transition-delay">
      <longdesc lang="en">Delay cluster recovery for this much time to allow for additional events to occur. Useful if your configuration is sensitive to the order in which ping updates arrive.</longdesc>
      <shortdesc lang="en">*** Advanced Use Only *** Enabling this option will slow down cluster recovery under all conditions</shortdesc>
      <content type="time" default="0s"/>
    </parameter>
    <parameter name="stonith-watchdog-timeout">
      <longdesc lang="en">If nonzero, along with `have-watchdog=true` automatically set by the cluster, when fencing is required, watchdog-based self-fencing will be performed via SBD without requiring a fencing resource explicitly configured. If `stonith-watchdog-timeout` is set to a positive value, unseen nodes are assumed to self-fence within this much time. +WARNING:+ It must be ensured that this value is larger than the `SBD_WATCHDOG_TIMEOUT` environment variable on all nodes. Pacemaker verifies the settings individually on all nodes and prevents startup or shuts down if configured wrongly on the fly. It&apos;s strongly recommended that `SBD_WATCHDOG_TIMEOUT` is set to the same value on all nodes. If `stonith-watchdog-timeout` is set to a negative value, and `SBD_WATCHDOG_TIMEOUT` is set, twice that value will be used. +WARNING:+ In this case, it&apos;s essential (currently not verified by Pacemaker) that `SBD_WATCHDOG_TIMEOUT` is set to the same value on all nodes.</longdesc>
      <shortdesc lang="en">How long to wait before we can assume nodes are safely down when watchdog-based self-fencing via SBD is in use</shortdesc>
      <content type="time" default="0"/>
    </parameter>
    <parameter name="stonith-max-attempts">
      <longdesc lang="en">How many times fencing can fail before it will no longer be immediately re-attempted on a target</longdesc>
      <shortdesc lang="en">How many times fencing can fail before it will no longer be immediately re-attempted on a target</shortdesc>
      <content type="integer" default="10"/>
    </parameter>
  </parameters>
</resource-agent>
